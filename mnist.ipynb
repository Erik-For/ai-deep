{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.flatten(x)\n",
    "        return self.linear_relu_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.3, inplace=False)\n",
      "    (11): Linear(in_features=256, out_features=10, bias=True)\n",
      "    (12): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model: NeuralNetwork = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for NeuralNetwork:\n\tMissing key(s) in state_dict: \"linear_relu_stack.3.weight\", \"linear_relu_stack.3.bias\", \"linear_relu_stack.5.weight\", \"linear_relu_stack.5.bias\", \"linear_relu_stack.11.weight\", \"linear_relu_stack.11.bias\". \n\tUnexpected key(s) in state_dict: \"linear_relu_stack.2.weight\", \"linear_relu_stack.2.bias\", \"linear_relu_stack.4.weight\", \"linear_relu_stack.4.bias\", \"linear_relu_stack.6.weight\", \"linear_relu_stack.6.bias\". \n\tsize mismatch for linear_relu_stack.8.weight: copying a param with shape torch.Size([10, 256]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for linear_relu_stack.8.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([256]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel3.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\x603e\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for NeuralNetwork:\n\tMissing key(s) in state_dict: \"linear_relu_stack.3.weight\", \"linear_relu_stack.3.bias\", \"linear_relu_stack.5.weight\", \"linear_relu_stack.5.bias\", \"linear_relu_stack.11.weight\", \"linear_relu_stack.11.bias\". \n\tUnexpected key(s) in state_dict: \"linear_relu_stack.2.weight\", \"linear_relu_stack.2.bias\", \"linear_relu_stack.4.weight\", \"linear_relu_stack.4.bias\", \"linear_relu_stack.6.weight\", \"linear_relu_stack.6.bias\". \n\tsize mismatch for linear_relu_stack.8.weight: copying a param with shape torch.Size([10, 256]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for linear_relu_stack.8.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([256])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model3.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimzer = torch.optim.SGD(model.parameters(), lr=1e-5, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimzer, step_size=5, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader: DataLoader, model: NeuralNetwork, loss_function, optimizer: torch.optim.Optimizer):\n",
    "    model.train()\n",
    "    m = len(dataloader.dataset)\n",
    "    epoch_cost = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = torch.squeeze(X).to(device), y.to(device)\n",
    "        \n",
    "\n",
    "        pred = model(X) # calculate predictions\n",
    "        loss = loss_function(pred, y) # calculate loss\n",
    "        epoch_cost += loss.item()\n",
    "\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # update parameters \n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{m:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader: DataLoader, model: NeuralNetwork, loss_function):\n",
    "    model.eval()\n",
    "    m = len(dataloader.dataset)\n",
    "    batch_count = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad(): # beräkna inte gradienter i onödan\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device) # flytta data till device t.ex. cuda dvs grafikkortet\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss = test_loss / batch_count\n",
    "    correct = correct / m\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300208 [    0/60000]\n",
      "loss: 2.305763 [ 3200/60000]\n",
      "loss: 2.304620 [ 6400/60000]\n",
      "loss: 2.301605 [ 9600/60000]\n",
      "loss: 2.297458 [12800/60000]\n",
      "loss: 2.299821 [16000/60000]\n",
      "loss: 2.308565 [19200/60000]\n",
      "loss: 2.303576 [22400/60000]\n",
      "loss: 2.302880 [25600/60000]\n",
      "loss: 2.296221 [28800/60000]\n",
      "loss: 2.302065 [32000/60000]\n",
      "loss: 2.298431 [35200/60000]\n",
      "loss: 2.293895 [38400/60000]\n",
      "loss: 2.300307 [41600/60000]\n",
      "loss: 2.305403 [44800/60000]\n",
      "loss: 2.299619 [48000/60000]\n",
      "loss: 2.301297 [51200/60000]\n",
      "loss: 2.301133 [54400/60000]\n",
      "loss: 2.295105 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 11.3%, Avg loss: 2.296418 \n",
      "\n",
      "Learning rate:  1e-05\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.296488 [    0/60000]\n",
      "loss: 2.303417 [ 3200/60000]\n",
      "loss: 2.295429 [ 6400/60000]\n",
      "loss: 2.296817 [ 9600/60000]\n",
      "loss: 2.291312 [12800/60000]\n",
      "loss: 2.295807 [16000/60000]\n",
      "loss: 2.303492 [19200/60000]\n",
      "loss: 2.293933 [22400/60000]\n",
      "loss: 2.297136 [25600/60000]\n",
      "loss: 2.275913 [28800/60000]\n",
      "loss: 2.291097 [32000/60000]\n",
      "loss: 2.293874 [35200/60000]\n",
      "loss: 2.275361 [38400/60000]\n",
      "loss: 2.280090 [41600/60000]\n",
      "loss: 2.295491 [44800/60000]\n",
      "loss: 2.281847 [48000/60000]\n",
      "loss: 2.290518 [51200/60000]\n",
      "loss: 2.281658 [54400/60000]\n",
      "loss: 2.276616 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 22.4%, Avg loss: 2.271888 \n",
      "\n",
      "Learning rate:  1e-05\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.272896 [    0/60000]\n",
      "loss: 2.282900 [ 3200/60000]\n",
      "loss: 2.266750 [ 6400/60000]\n",
      "loss: 2.276034 [ 9600/60000]\n",
      "loss: 2.266988 [12800/60000]\n",
      "loss: 2.267079 [16000/60000]\n",
      "loss: 2.276292 [19200/60000]\n",
      "loss: 2.242411 [22400/60000]\n",
      "loss: 2.244110 [25600/60000]\n",
      "loss: 2.212547 [28800/60000]\n",
      "loss: 2.235866 [32000/60000]\n",
      "loss: 2.238065 [35200/60000]\n",
      "loss: 2.185215 [38400/60000]\n",
      "loss: 2.209254 [41600/60000]\n",
      "loss: 2.224366 [44800/60000]\n",
      "loss: 2.173329 [48000/60000]\n",
      "loss: 2.189388 [51200/60000]\n",
      "loss: 2.138218 [54400/60000]\n",
      "loss: 2.106736 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 2.089286 \n",
      "\n",
      "Learning rate:  1e-05\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.103618 [    0/60000]\n",
      "loss: 2.121340 [ 3200/60000]\n",
      "loss: 2.057088 [ 6400/60000]\n",
      "loss: 2.068994 [ 9600/60000]\n",
      "loss: 1.978743 [12800/60000]\n",
      "loss: 1.985112 [16000/60000]\n",
      "loss: 1.990617 [19200/60000]\n",
      "loss: 1.800174 [22400/60000]\n",
      "loss: 1.788163 [25600/60000]\n",
      "loss: 1.552040 [28800/60000]\n",
      "loss: 1.675552 [32000/60000]\n",
      "loss: 1.625260 [35200/60000]\n",
      "loss: 1.317976 [38400/60000]\n",
      "loss: 1.527921 [41600/60000]\n",
      "loss: 1.632035 [44800/60000]\n",
      "loss: 1.390696 [48000/60000]\n",
      "loss: 1.778728 [51200/60000]\n",
      "loss: 1.498872 [54400/60000]\n",
      "loss: 1.263498 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.372382 \n",
      "\n",
      "Learning rate:  1e-05\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.514293 [    0/60000]\n",
      "loss: 1.411919 [ 3200/60000]\n",
      "loss: 1.572244 [ 6400/60000]\n",
      "loss: 1.445449 [ 9600/60000]\n",
      "loss: 1.139156 [12800/60000]\n",
      "loss: 1.620303 [16000/60000]\n",
      "loss: 1.477078 [19200/60000]\n",
      "loss: 1.102141 [22400/60000]\n",
      "loss: 1.203746 [25600/60000]\n",
      "loss: 0.811494 [28800/60000]\n",
      "loss: 1.040907 [32000/60000]\n",
      "loss: 1.077423 [35200/60000]\n",
      "loss: 0.987383 [38400/60000]\n",
      "loss: 0.849550 [41600/60000]\n",
      "loss: 0.946653 [44800/60000]\n",
      "loss: 0.915531 [48000/60000]\n",
      "loss: 1.070468 [51200/60000]\n",
      "loss: 1.056428 [54400/60000]\n",
      "loss: 1.138676 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.841117 \n",
      "\n",
      "Learning rate:  1e-05\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.871372 [    0/60000]\n",
      "loss: 0.674295 [ 3200/60000]\n",
      "loss: 0.822849 [ 6400/60000]\n",
      "loss: 1.022045 [ 9600/60000]\n",
      "loss: 0.691363 [12800/60000]\n",
      "loss: 1.252382 [16000/60000]\n",
      "loss: 1.018417 [19200/60000]\n",
      "loss: 0.565607 [22400/60000]\n",
      "loss: 0.966776 [25600/60000]\n",
      "loss: 0.479190 [28800/60000]\n",
      "loss: 0.961543 [32000/60000]\n",
      "loss: 0.983956 [35200/60000]\n",
      "loss: 0.692740 [38400/60000]\n",
      "loss: 0.731500 [41600/60000]\n",
      "loss: 0.744579 [44800/60000]\n",
      "loss: 0.925385 [48000/60000]\n",
      "loss: 1.068136 [51200/60000]\n",
      "loss: 0.665051 [54400/60000]\n",
      "loss: 0.980532 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.639084 \n",
      "\n",
      "Learning rate:  9.9e-06\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.754317 [    0/60000]\n",
      "loss: 0.607240 [ 3200/60000]\n",
      "loss: 0.609822 [ 6400/60000]\n",
      "loss: 1.011633 [ 9600/60000]\n",
      "loss: 0.535275 [12800/60000]\n",
      "loss: 1.117557 [16000/60000]\n",
      "loss: 0.831645 [19200/60000]\n",
      "loss: 0.545953 [22400/60000]\n",
      "loss: 0.655969 [25600/60000]\n",
      "loss: 0.410753 [28800/60000]\n",
      "loss: 0.609433 [32000/60000]\n",
      "loss: 0.677326 [35200/60000]\n",
      "loss: 0.466320 [38400/60000]\n",
      "loss: 0.640094 [41600/60000]\n",
      "loss: 0.601584 [44800/60000]\n",
      "loss: 0.462010 [48000/60000]\n",
      "loss: 0.592902 [51200/60000]\n",
      "loss: 0.624103 [54400/60000]\n",
      "loss: 1.018747 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.517061 \n",
      "\n",
      "Learning rate:  9.9e-06\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.686192 [    0/60000]\n",
      "loss: 0.583674 [ 3200/60000]\n",
      "loss: 0.552359 [ 6400/60000]\n",
      "loss: 0.823987 [ 9600/60000]\n",
      "loss: 0.411822 [12800/60000]\n",
      "loss: 0.933001 [16000/60000]\n",
      "loss: 0.634470 [19200/60000]\n",
      "loss: 0.382968 [22400/60000]\n",
      "loss: 0.473969 [25600/60000]\n",
      "loss: 0.429168 [28800/60000]\n",
      "loss: 0.556340 [32000/60000]\n",
      "loss: 0.574191 [35200/60000]\n",
      "loss: 0.275656 [38400/60000]\n",
      "loss: 0.490892 [41600/60000]\n",
      "loss: 0.388872 [44800/60000]\n",
      "loss: 0.306359 [48000/60000]\n",
      "loss: 0.586919 [51200/60000]\n",
      "loss: 0.603511 [54400/60000]\n",
      "loss: 1.039813 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.410196 \n",
      "\n",
      "Learning rate:  9.9e-06\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.642469 [    0/60000]\n",
      "loss: 0.470418 [ 3200/60000]\n",
      "loss: 0.500890 [ 6400/60000]\n",
      "loss: 0.646513 [ 9600/60000]\n",
      "loss: 0.305519 [12800/60000]\n",
      "loss: 0.645300 [16000/60000]\n",
      "loss: 0.626147 [19200/60000]\n",
      "loss: 0.215507 [22400/60000]\n",
      "loss: 0.376838 [25600/60000]\n",
      "loss: 0.283503 [28800/60000]\n",
      "loss: 0.509730 [32000/60000]\n",
      "loss: 0.589880 [35200/60000]\n",
      "loss: 0.184308 [38400/60000]\n",
      "loss: 0.323699 [41600/60000]\n",
      "loss: 0.356278 [44800/60000]\n",
      "loss: 0.342478 [48000/60000]\n",
      "loss: 0.374294 [51200/60000]\n",
      "loss: 0.451563 [54400/60000]\n",
      "loss: 0.642497 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.317147 \n",
      "\n",
      "Learning rate:  9.9e-06\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.476781 [    0/60000]\n",
      "loss: 0.305607 [ 3200/60000]\n",
      "loss: 0.265674 [ 6400/60000]\n",
      "loss: 0.831356 [ 9600/60000]\n",
      "loss: 0.294936 [12800/60000]\n",
      "loss: 0.630470 [16000/60000]\n",
      "loss: 0.476669 [19200/60000]\n",
      "loss: 0.255666 [22400/60000]\n",
      "loss: 0.386602 [25600/60000]\n",
      "loss: 0.220629 [28800/60000]\n",
      "loss: 0.441489 [32000/60000]\n",
      "loss: 0.461349 [35200/60000]\n",
      "loss: 0.300236 [38400/60000]\n",
      "loss: 0.242390 [41600/60000]\n",
      "loss: 0.264104 [44800/60000]\n",
      "loss: 0.374589 [48000/60000]\n",
      "loss: 0.321087 [51200/60000]\n",
      "loss: 0.177169 [54400/60000]\n",
      "loss: 0.417005 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.264067 \n",
      "\n",
      "Learning rate:  9.9e-06\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.283686 [    0/60000]\n",
      "loss: 0.302549 [ 3200/60000]\n",
      "loss: 0.467567 [ 6400/60000]\n",
      "loss: 0.420874 [ 9600/60000]\n",
      "loss: 0.236321 [12800/60000]\n",
      "loss: 0.664099 [16000/60000]\n",
      "loss: 0.331502 [19200/60000]\n",
      "loss: 0.273475 [22400/60000]\n",
      "loss: 0.273969 [25600/60000]\n",
      "loss: 0.129164 [28800/60000]\n",
      "loss: 0.297156 [32000/60000]\n",
      "loss: 0.553731 [35200/60000]\n",
      "loss: 0.219300 [38400/60000]\n",
      "loss: 0.357330 [41600/60000]\n",
      "loss: 0.311200 [44800/60000]\n",
      "loss: 0.209981 [48000/60000]\n",
      "loss: 0.177273 [51200/60000]\n",
      "loss: 0.274362 [54400/60000]\n",
      "loss: 0.609744 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.238378 \n",
      "\n",
      "Learning rate:  9.801e-06\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.168154 [    0/60000]\n",
      "loss: 0.339728 [ 3200/60000]\n",
      "loss: 0.271028 [ 6400/60000]\n",
      "loss: 0.481356 [ 9600/60000]\n",
      "loss: 0.161650 [12800/60000]\n",
      "loss: 0.594616 [16000/60000]\n",
      "loss: 0.502596 [19200/60000]\n",
      "loss: 0.108204 [22400/60000]\n",
      "loss: 0.230152 [25600/60000]\n",
      "loss: 0.221507 [28800/60000]\n",
      "loss: 0.359111 [32000/60000]\n",
      "loss: 0.455286 [35200/60000]\n",
      "loss: 0.194356 [38400/60000]\n",
      "loss: 0.212175 [41600/60000]\n",
      "loss: 0.351470 [44800/60000]\n",
      "loss: 0.207943 [48000/60000]\n",
      "loss: 0.295363 [51200/60000]\n",
      "loss: 0.214836 [54400/60000]\n",
      "loss: 0.424660 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.196266 \n",
      "\n",
      "Learning rate:  9.801e-06\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.137156 [    0/60000]\n",
      "loss: 0.299141 [ 3200/60000]\n",
      "loss: 0.165108 [ 6400/60000]\n",
      "loss: 0.219624 [ 9600/60000]\n",
      "loss: 0.173831 [12800/60000]\n",
      "loss: 0.473789 [16000/60000]\n",
      "loss: 0.441069 [19200/60000]\n",
      "loss: 0.216386 [22400/60000]\n",
      "loss: 0.273910 [25600/60000]\n",
      "loss: 0.148917 [28800/60000]\n",
      "loss: 0.266937 [32000/60000]\n",
      "loss: 0.309984 [35200/60000]\n",
      "loss: 0.100917 [38400/60000]\n",
      "loss: 0.212321 [41600/60000]\n",
      "loss: 0.234819 [44800/60000]\n",
      "loss: 0.214604 [48000/60000]\n",
      "loss: 0.153190 [51200/60000]\n",
      "loss: 0.140173 [54400/60000]\n",
      "loss: 0.373196 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.179592 \n",
      "\n",
      "Learning rate:  9.801e-06\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.321142 [    0/60000]\n",
      "loss: 0.158612 [ 3200/60000]\n",
      "loss: 0.255851 [ 6400/60000]\n",
      "loss: 0.218436 [ 9600/60000]\n",
      "loss: 0.143441 [12800/60000]\n",
      "loss: 0.424313 [16000/60000]\n",
      "loss: 0.340385 [19200/60000]\n",
      "loss: 0.149587 [22400/60000]\n",
      "loss: 0.160806 [25600/60000]\n",
      "loss: 0.162934 [28800/60000]\n",
      "loss: 0.249380 [32000/60000]\n",
      "loss: 0.291272 [35200/60000]\n",
      "loss: 0.067052 [38400/60000]\n",
      "loss: 0.240231 [41600/60000]\n",
      "loss: 0.284354 [44800/60000]\n",
      "loss: 0.092947 [48000/60000]\n",
      "loss: 0.128843 [51200/60000]\n",
      "loss: 0.217741 [54400/60000]\n",
      "loss: 0.568273 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.167366 \n",
      "\n",
      "Learning rate:  9.801e-06\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.238922 [    0/60000]\n",
      "loss: 0.133637 [ 3200/60000]\n",
      "loss: 0.295858 [ 6400/60000]\n",
      "loss: 0.176256 [ 9600/60000]\n",
      "loss: 0.121985 [12800/60000]\n",
      "loss: 0.380084 [16000/60000]\n",
      "loss: 0.237880 [19200/60000]\n",
      "loss: 0.120692 [22400/60000]\n",
      "loss: 0.125497 [25600/60000]\n",
      "loss: 0.211115 [28800/60000]\n",
      "loss: 0.318880 [32000/60000]\n",
      "loss: 0.318201 [35200/60000]\n",
      "loss: 0.071930 [38400/60000]\n",
      "loss: 0.197521 [41600/60000]\n",
      "loss: 0.288333 [44800/60000]\n",
      "loss: 0.073061 [48000/60000]\n",
      "loss: 0.048266 [51200/60000]\n",
      "loss: 0.063792 [54400/60000]\n",
      "loss: 0.623226 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.163483 \n",
      "\n",
      "Learning rate:  9.801e-06\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.183578 [    0/60000]\n",
      "loss: 0.226203 [ 3200/60000]\n",
      "loss: 0.131085 [ 6400/60000]\n",
      "loss: 0.288868 [ 9600/60000]\n",
      "loss: 0.135681 [12800/60000]\n",
      "loss: 0.180398 [16000/60000]\n",
      "loss: 0.291111 [19200/60000]\n",
      "loss: 0.111072 [22400/60000]\n",
      "loss: 0.073301 [25600/60000]\n",
      "loss: 0.141125 [28800/60000]\n",
      "loss: 0.283415 [32000/60000]\n",
      "loss: 0.347122 [35200/60000]\n",
      "loss: 0.103250 [38400/60000]\n",
      "loss: 0.178269 [41600/60000]\n",
      "loss: 0.230497 [44800/60000]\n",
      "loss: 0.150091 [48000/60000]\n",
      "loss: 0.179536 [51200/60000]\n",
      "loss: 0.200606 [54400/60000]\n",
      "loss: 0.285605 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.139916 \n",
      "\n",
      "Learning rate:  9.70299e-06\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.128039 [    0/60000]\n",
      "loss: 0.214816 [ 3200/60000]\n",
      "loss: 0.238038 [ 6400/60000]\n",
      "loss: 0.182430 [ 9600/60000]\n",
      "loss: 0.078484 [12800/60000]\n",
      "loss: 0.433951 [16000/60000]\n",
      "loss: 0.270019 [19200/60000]\n",
      "loss: 0.157976 [22400/60000]\n",
      "loss: 0.138753 [25600/60000]\n",
      "loss: 0.107298 [28800/60000]\n",
      "loss: 0.199939 [32000/60000]\n",
      "loss: 0.245683 [35200/60000]\n",
      "loss: 0.068194 [38400/60000]\n",
      "loss: 0.191440 [41600/60000]\n",
      "loss: 0.260626 [44800/60000]\n",
      "loss: 0.186734 [48000/60000]\n",
      "loss: 0.171934 [51200/60000]\n",
      "loss: 0.106128 [54400/60000]\n",
      "loss: 0.326208 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.127335 \n",
      "\n",
      "Learning rate:  9.70299e-06\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.101330 [    0/60000]\n",
      "loss: 0.079408 [ 3200/60000]\n",
      "loss: 0.372188 [ 6400/60000]\n",
      "loss: 0.116651 [ 9600/60000]\n",
      "loss: 0.079035 [12800/60000]\n",
      "loss: 0.369067 [16000/60000]\n",
      "loss: 0.178208 [19200/60000]\n",
      "loss: 0.080767 [22400/60000]\n",
      "loss: 0.019455 [25600/60000]\n",
      "loss: 0.062463 [28800/60000]\n",
      "loss: 0.183781 [32000/60000]\n",
      "loss: 0.266537 [35200/60000]\n",
      "loss: 0.058604 [38400/60000]\n",
      "loss: 0.079218 [41600/60000]\n",
      "loss: 0.200601 [44800/60000]\n",
      "loss: 0.066391 [48000/60000]\n",
      "loss: 0.217581 [51200/60000]\n",
      "loss: 0.025796 [54400/60000]\n",
      "loss: 0.204133 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.133506 \n",
      "\n",
      "Learning rate:  9.70299e-06\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.351099 [    0/60000]\n",
      "loss: 0.143902 [ 3200/60000]\n",
      "loss: 0.446876 [ 6400/60000]\n",
      "loss: 0.040876 [ 9600/60000]\n",
      "loss: 0.047725 [12800/60000]\n",
      "loss: 0.195179 [16000/60000]\n",
      "loss: 0.197903 [19200/60000]\n",
      "loss: 0.066276 [22400/60000]\n",
      "loss: 0.087141 [25600/60000]\n",
      "loss: 0.010125 [28800/60000]\n",
      "loss: 0.167726 [32000/60000]\n",
      "loss: 0.346996 [35200/60000]\n",
      "loss: 0.038678 [38400/60000]\n",
      "loss: 0.047880 [41600/60000]\n",
      "loss: 0.266342 [44800/60000]\n",
      "loss: 0.132831 [48000/60000]\n",
      "loss: 0.150306 [51200/60000]\n",
      "loss: 0.138181 [54400/60000]\n",
      "loss: 0.173257 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.117971 \n",
      "\n",
      "Learning rate:  9.70299e-06\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.039827 [    0/60000]\n",
      "loss: 0.098759 [ 3200/60000]\n",
      "loss: 0.273571 [ 6400/60000]\n",
      "loss: 0.055202 [ 9600/60000]\n",
      "loss: 0.123330 [12800/60000]\n",
      "loss: 0.183064 [16000/60000]\n",
      "loss: 0.202420 [19200/60000]\n",
      "loss: 0.096894 [22400/60000]\n",
      "loss: 0.026277 [25600/60000]\n",
      "loss: 0.032021 [28800/60000]\n",
      "loss: 0.403387 [32000/60000]\n",
      "loss: 0.110566 [35200/60000]\n",
      "loss: 0.046008 [38400/60000]\n",
      "loss: 0.058361 [41600/60000]\n",
      "loss: 0.183299 [44800/60000]\n",
      "loss: 0.137314 [48000/60000]\n",
      "loss: 0.179629 [51200/60000]\n",
      "loss: 0.018784 [54400/60000]\n",
      "loss: 0.323019 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.120199 \n",
      "\n",
      "Learning rate:  9.70299e-06\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.066134 [    0/60000]\n",
      "loss: 0.021789 [ 3200/60000]\n",
      "loss: 0.160097 [ 6400/60000]\n",
      "loss: 0.100666 [ 9600/60000]\n",
      "loss: 0.133603 [12800/60000]\n",
      "loss: 0.200620 [16000/60000]\n",
      "loss: 0.265072 [19200/60000]\n",
      "loss: 0.039490 [22400/60000]\n",
      "loss: 0.093218 [25600/60000]\n",
      "loss: 0.046861 [28800/60000]\n",
      "loss: 0.222180 [32000/60000]\n",
      "loss: 0.205199 [35200/60000]\n",
      "loss: 0.071753 [38400/60000]\n",
      "loss: 0.088873 [41600/60000]\n",
      "loss: 0.253758 [44800/60000]\n",
      "loss: 0.145856 [48000/60000]\n",
      "loss: 0.193454 [51200/60000]\n",
      "loss: 0.016673 [54400/60000]\n",
      "loss: 0.373141 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.111492 \n",
      "\n",
      "Learning rate:  9.6059601e-06\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.052202 [    0/60000]\n",
      "loss: 0.052241 [ 3200/60000]\n",
      "loss: 0.366038 [ 6400/60000]\n",
      "loss: 0.076798 [ 9600/60000]\n",
      "loss: 0.041080 [12800/60000]\n",
      "loss: 0.294820 [16000/60000]\n",
      "loss: 0.082609 [19200/60000]\n",
      "loss: 0.041160 [22400/60000]\n",
      "loss: 0.092572 [25600/60000]\n",
      "loss: 0.042800 [28800/60000]\n",
      "loss: 0.115301 [32000/60000]\n",
      "loss: 0.185132 [35200/60000]\n",
      "loss: 0.077158 [38400/60000]\n",
      "loss: 0.140382 [41600/60000]\n",
      "loss: 0.278759 [44800/60000]\n",
      "loss: 0.206329 [48000/60000]\n",
      "loss: 0.207844 [51200/60000]\n",
      "loss: 0.252826 [54400/60000]\n",
      "loss: 0.095271 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.115213 \n",
      "\n",
      "Learning rate:  9.6059601e-06\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.098724 [    0/60000]\n",
      "loss: 0.058972 [ 3200/60000]\n",
      "loss: 0.336989 [ 6400/60000]\n",
      "loss: 0.067530 [ 9600/60000]\n",
      "loss: 0.064607 [12800/60000]\n",
      "loss: 0.211835 [16000/60000]\n",
      "loss: 0.076326 [19200/60000]\n",
      "loss: 0.045725 [22400/60000]\n",
      "loss: 0.070100 [25600/60000]\n",
      "loss: 0.072118 [28800/60000]\n",
      "loss: 0.142572 [32000/60000]\n",
      "loss: 0.063623 [35200/60000]\n",
      "loss: 0.062926 [38400/60000]\n",
      "loss: 0.038263 [41600/60000]\n",
      "loss: 0.183195 [44800/60000]\n",
      "loss: 0.063438 [48000/60000]\n",
      "loss: 0.265523 [51200/60000]\n",
      "loss: 0.011606 [54400/60000]\n",
      "loss: 0.214296 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.114105 \n",
      "\n",
      "Learning rate:  9.6059601e-06\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.077101 [    0/60000]\n",
      "loss: 0.057481 [ 3200/60000]\n",
      "loss: 0.188671 [ 6400/60000]\n",
      "loss: 0.077834 [ 9600/60000]\n",
      "loss: 0.087321 [12800/60000]\n",
      "loss: 0.151554 [16000/60000]\n",
      "loss: 0.086392 [19200/60000]\n",
      "loss: 0.039323 [22400/60000]\n",
      "loss: 0.092058 [25600/60000]\n",
      "loss: 0.008591 [28800/60000]\n",
      "loss: 0.057944 [32000/60000]\n",
      "loss: 0.147545 [35200/60000]\n",
      "loss: 0.094267 [38400/60000]\n",
      "loss: 0.089299 [41600/60000]\n",
      "loss: 0.340522 [44800/60000]\n",
      "loss: 0.067882 [48000/60000]\n",
      "loss: 0.240932 [51200/60000]\n",
      "loss: 0.092371 [54400/60000]\n",
      "loss: 0.209219 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.105232 \n",
      "\n",
      "Learning rate:  9.6059601e-06\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.033301 [    0/60000]\n",
      "loss: 0.054758 [ 3200/60000]\n",
      "loss: 0.296745 [ 6400/60000]\n",
      "loss: 0.058487 [ 9600/60000]\n",
      "loss: 0.132493 [12800/60000]\n",
      "loss: 0.163744 [16000/60000]\n",
      "loss: 0.138501 [19200/60000]\n",
      "loss: 0.065052 [22400/60000]\n",
      "loss: 0.092665 [25600/60000]\n",
      "loss: 0.013333 [28800/60000]\n",
      "loss: 0.168284 [32000/60000]\n",
      "loss: 0.080095 [35200/60000]\n",
      "loss: 0.109082 [38400/60000]\n",
      "loss: 0.049194 [41600/60000]\n",
      "loss: 0.158475 [44800/60000]\n",
      "loss: 0.154275 [48000/60000]\n",
      "loss: 0.076342 [51200/60000]\n",
      "loss: 0.205027 [54400/60000]\n",
      "loss: 0.322832 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.099782 \n",
      "\n",
      "Learning rate:  9.6059601e-06\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.138069 [    0/60000]\n",
      "loss: 0.109521 [ 3200/60000]\n",
      "loss: 0.236957 [ 6400/60000]\n",
      "loss: 0.185217 [ 9600/60000]\n",
      "loss: 0.092372 [12800/60000]\n",
      "loss: 0.247922 [16000/60000]\n",
      "loss: 0.337820 [19200/60000]\n",
      "loss: 0.037110 [22400/60000]\n",
      "loss: 0.083552 [25600/60000]\n",
      "loss: 0.034770 [28800/60000]\n",
      "loss: 0.120025 [32000/60000]\n",
      "loss: 0.342005 [35200/60000]\n",
      "loss: 0.035754 [38400/60000]\n",
      "loss: 0.044603 [41600/60000]\n",
      "loss: 0.167439 [44800/60000]\n",
      "loss: 0.135419 [48000/60000]\n",
      "loss: 0.149798 [51200/60000]\n",
      "loss: 0.136962 [54400/60000]\n",
      "loss: 0.079642 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.102264 \n",
      "\n",
      "Learning rate:  9.509900499e-06\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.033699 [    0/60000]\n",
      "loss: 0.025805 [ 3200/60000]\n",
      "loss: 0.473090 [ 6400/60000]\n",
      "loss: 0.067370 [ 9600/60000]\n",
      "loss: 0.084457 [12800/60000]\n",
      "loss: 0.213536 [16000/60000]\n",
      "loss: 0.259458 [19200/60000]\n",
      "loss: 0.058192 [22400/60000]\n",
      "loss: 0.038674 [25600/60000]\n",
      "loss: 0.008985 [28800/60000]\n",
      "loss: 0.104036 [32000/60000]\n",
      "loss: 0.134092 [35200/60000]\n",
      "loss: 0.009669 [38400/60000]\n",
      "loss: 0.064605 [41600/60000]\n",
      "loss: 0.105051 [44800/60000]\n",
      "loss: 0.047857 [48000/60000]\n",
      "loss: 0.089040 [51200/60000]\n",
      "loss: 0.069417 [54400/60000]\n",
      "loss: 0.121072 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.102017 \n",
      "\n",
      "Learning rate:  9.509900499e-06\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.038064 [    0/60000]\n",
      "loss: 0.031742 [ 3200/60000]\n",
      "loss: 0.233184 [ 6400/60000]\n",
      "loss: 0.022513 [ 9600/60000]\n",
      "loss: 0.056855 [12800/60000]\n",
      "loss: 0.304589 [16000/60000]\n",
      "loss: 0.732711 [19200/60000]\n",
      "loss: 0.052068 [22400/60000]\n",
      "loss: 0.007149 [25600/60000]\n",
      "loss: 0.007267 [28800/60000]\n",
      "loss: 0.067878 [32000/60000]\n",
      "loss: 0.215756 [35200/60000]\n",
      "loss: 0.067492 [38400/60000]\n",
      "loss: 0.053138 [41600/60000]\n",
      "loss: 0.069517 [44800/60000]\n",
      "loss: 0.037691 [48000/60000]\n",
      "loss: 0.053820 [51200/60000]\n",
      "loss: 0.022660 [54400/60000]\n",
      "loss: 0.425255 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.109647 \n",
      "\n",
      "Learning rate:  9.509900499e-06\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.009166 [    0/60000]\n",
      "loss: 0.016876 [ 3200/60000]\n",
      "loss: 0.229910 [ 6400/60000]\n",
      "loss: 0.062349 [ 9600/60000]\n",
      "loss: 0.058470 [12800/60000]\n",
      "loss: 0.142383 [16000/60000]\n",
      "loss: 0.120899 [19200/60000]\n",
      "loss: 0.046627 [22400/60000]\n",
      "loss: 0.057125 [25600/60000]\n",
      "loss: 0.004591 [28800/60000]\n",
      "loss: 0.119593 [32000/60000]\n",
      "loss: 0.325335 [35200/60000]\n",
      "loss: 0.014745 [38400/60000]\n",
      "loss: 0.051472 [41600/60000]\n",
      "loss: 0.040237 [44800/60000]\n",
      "loss: 0.082314 [48000/60000]\n",
      "loss: 0.298485 [51200/60000]\n",
      "loss: 0.054164 [54400/60000]\n",
      "loss: 0.070796 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.107787 \n",
      "\n",
      "Learning rate:  9.509900499e-06\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.008549 [    0/60000]\n",
      "loss: 0.108307 [ 3200/60000]\n",
      "loss: 0.225614 [ 6400/60000]\n",
      "loss: 0.028185 [ 9600/60000]\n",
      "loss: 0.129168 [12800/60000]\n",
      "loss: 0.122577 [16000/60000]\n",
      "loss: 0.315079 [19200/60000]\n",
      "loss: 0.027606 [22400/60000]\n",
      "loss: 0.064502 [25600/60000]\n",
      "loss: 0.007519 [28800/60000]\n",
      "loss: 0.157455 [32000/60000]\n",
      "loss: 0.477318 [35200/60000]\n",
      "loss: 0.033465 [38400/60000]\n",
      "loss: 0.063119 [41600/60000]\n",
      "loss: 0.123928 [44800/60000]\n",
      "loss: 0.023116 [48000/60000]\n",
      "loss: 0.167023 [51200/60000]\n",
      "loss: 0.011102 [54400/60000]\n",
      "loss: 0.084899 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.109045 \n",
      "\n",
      "Learning rate:  9.509900499e-06\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.016175 [    0/60000]\n",
      "loss: 0.026186 [ 3200/60000]\n",
      "loss: 0.135150 [ 6400/60000]\n",
      "loss: 0.051671 [ 9600/60000]\n",
      "loss: 0.156585 [12800/60000]\n",
      "loss: 0.196060 [16000/60000]\n",
      "loss: 0.138713 [19200/60000]\n",
      "loss: 0.123177 [22400/60000]\n",
      "loss: 0.012401 [25600/60000]\n",
      "loss: 0.078203 [28800/60000]\n",
      "loss: 0.033763 [32000/60000]\n",
      "loss: 0.286237 [35200/60000]\n",
      "loss: 0.009709 [38400/60000]\n",
      "loss: 0.060335 [41600/60000]\n",
      "loss: 0.118764 [44800/60000]\n",
      "loss: 0.081988 [48000/60000]\n",
      "loss: 0.317352 [51200/60000]\n",
      "loss: 0.030890 [54400/60000]\n",
      "loss: 0.131681 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.102260 \n",
      "\n",
      "Learning rate:  9.414801494009999e-06\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.007924 [    0/60000]\n",
      "loss: 0.111869 [ 3200/60000]\n",
      "loss: 0.096779 [ 6400/60000]\n",
      "loss: 0.080117 [ 9600/60000]\n",
      "loss: 0.204205 [12800/60000]\n",
      "loss: 0.103294 [16000/60000]\n",
      "loss: 0.083067 [19200/60000]\n",
      "loss: 0.012771 [22400/60000]\n",
      "loss: 0.107274 [25600/60000]\n",
      "loss: 0.068099 [28800/60000]\n",
      "loss: 0.014845 [32000/60000]\n",
      "loss: 0.047561 [35200/60000]\n",
      "loss: 0.027462 [38400/60000]\n",
      "loss: 0.101239 [41600/60000]\n",
      "loss: 0.077532 [44800/60000]\n",
      "loss: 0.067666 [48000/60000]\n",
      "loss: 0.100181 [51200/60000]\n",
      "loss: 0.016516 [54400/60000]\n",
      "loss: 0.006664 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.101389 \n",
      "\n",
      "Learning rate:  9.414801494009999e-06\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.014655 [    0/60000]\n",
      "loss: 0.006750 [ 3200/60000]\n",
      "loss: 0.213244 [ 6400/60000]\n",
      "loss: 0.023154 [ 9600/60000]\n",
      "loss: 0.094759 [12800/60000]\n",
      "loss: 0.191548 [16000/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimzer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     test(test_dataloader, model, loss_function)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning rate: \u001b[39m\u001b[38;5;124m\"\u001b[39m, optimzer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[58], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_function, optimizer)\u001b[0m\n\u001b[0;32m      3\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m      4\u001b[0m epoch_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# calculate predictions\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\x603e\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\x603e\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\x603e\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\x603e\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\x603e\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\x603e\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    171\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[1;32m--> 172\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_function, optimzer)\n",
    "    test(test_dataloader, model, loss_function)\n",
    "    print(\"Learning rate: \", optimzer.param_groups[0]['lr'])\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/x603e/code/notebook\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model3.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bias(model: NeuralNetwork, train_dataloader: DataLoader, test_dataloader: DataLoader):\n",
    "    model.eval()\n",
    "    train_acc, test_acc = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in train_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            train_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    train_acc = (train_acc / len(train_dataloader.dataset)) * 100\n",
    "    test_acc = (test_acc / len(test_dataloader.dataset)) * 100\n",
    "    #return train_acc, test_acc, abs(train_acc - test_acc)\n",
    "    print(f\"Train Accuracy: {train_acc:>0.3f}%, Test Accuracy: {test_acc:>0.3f}%, Difference/Bias: {abs(train_acc - test_acc):>0.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98.982%, Test Accuracy: 97.820%, Difference/Bias: 1.162%\n"
     ]
    }
   ],
   "source": [
    "calc_bias(model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
